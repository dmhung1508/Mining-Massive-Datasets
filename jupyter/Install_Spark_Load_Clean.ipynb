{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07e3c6d5",
   "metadata": {},
   "source": [
    "# C√†i Spark, load d·ªØ li·ªáu Ukraine tweets (~40GB), clean r·ªìi l∆∞u Parquet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77cec8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setx HADOOP_HOME: SUCCESS: Specified value was saved.\n",
      "HADOOP_HOME (system) = ''\n",
      "\n",
      "‚ö† Ch·∫°y PowerShell as Administrator r·ªìi ch·∫°y l·ªánh:\n",
      "  [System.Environment]::SetEnvironmentVariable(\"HADOOP_HOME\",\"C:\\hadoop\",\"Machine\")\n",
      "  Sau ƒë√≥ restart Jupyter.\n"
     ]
    }
   ],
   "source": [
    "import subprocess, urllib.request, os\n",
    "from pathlib import Path\n",
    "\n",
    "# winutils c·∫ßn thi·∫øt ƒë·ªÉ Spark ch·∫°y tr√™n Windows\n",
    "hadoop_bin = Path(r\"C:\\hadoop\\bin\")\n",
    "hadoop_bin.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for name, url in [\n",
    "    (\"winutils.exe\", \"https://github.com/cdarlint/winutils/raw/master/hadoop-3.3.6/bin/winutils.exe\"),\n",
    "    (\"hadoop.dll\",   \"https://github.com/cdarlint/winutils/raw/master/hadoop-3.3.6/bin/hadoop.dll\"),\n",
    "]:\n",
    "    f = hadoop_bin / name\n",
    "    if not f.exists():\n",
    "        print(f\"downloading {name}...\")\n",
    "        urllib.request.urlretrieve(url, f)\n",
    "\n",
    "subprocess.run([\"setx\", \"HADOOP_HOME\", r\"C:\\hadoop\"], capture_output=True)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ce052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HADOOP_HOME\"] = r\"C:\\hadoop\"\n",
    "os.environ[\"PATH\"] = r\"C:\\hadoop\\bin;\" + os.environ.get(\"PATH\", \"\")\n",
    "\n",
    "from pathlib import Path\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "DATA_DIR = Path(r\"F:\\UK-Russia\\Data\")\n",
    "OUT_DIR  = Path(r\"F:\\UK-Russia\\jupyter\\output\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PARQUET_OUT = OUT_DIR / \"tweets_clean.parquet\"\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"ukraine_etl\")\n",
    "    .config(\"spark.driver.memory\", \"8g\")\n",
    "    .config(\"spark.executor.memory\", \"8g\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"40\")\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "    .config(\"spark.sql.parquet.compression.codec\", \"snappy\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "print(spark.version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6a32d6",
   "metadata": {},
   "source": [
    "## ETL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc03d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['_c0', 'userid', 'username', 'acctdesc', 'location', 'following', 'followers', 'totaltweets', 'usercreatedts', 'tweetid', 'tweetcreatedts', 'retweetcount', 'text', 'hashtags', 'language', 'coordinates', 'favorite_count', 'is_retweet', 'original_tweet_id', 'original_tweet_userid', 'original_tweet_username', 'in_reply_to_status_id', 'in_reply_to_user_id', 'in_reply_to_screen_name', 'is_quote_status', 'quoted_status_id', 'quoted_status_userid', 'quoted_status_username', 'extractedts']\n",
      "\n",
      "Total columns: 29\n",
      "+-------------------+------------------------------------------------------------+--------+------------------------------------------------------------+\n",
      "|            tweetid|                                                        text|language|                                                    hashtags|\n",
      "+-------------------+------------------------------------------------------------+--------+------------------------------------------------------------+\n",
      "|1560416252937617411|Dear vaccine advocate\\n\\nDo take the COVID19 mRNA shot an...|      en|[{'text': 'Pfizer', 'indices': [189, 196]}, {'text': 'Ast...|\n",
      "|1560416256179707904|#Mundo \\n\\nAl menos 6 muertos y 16 heridos en bombardeo r...|      es|[{'text': 'Mundo', 'indices': [0, 6]}, {'text': 'Kharkiv'...|\n",
      "|1560416257752666113|Animal shelter Dogs and Cats, we need your help!\\nRaising...|      en|[{'text': 'Ukraine', 'indices': [189, 197]}, {'text': 'Pa...|\n",
      "+-------------------+------------------------------------------------------------+--------+------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ki·ªÉm tra nhanh c·ªôt c·ªßa file csv\n",
    "sample = spark.read.option(\"header\",\"true\").option(\"multiLine\",\"true\").option(\"escape\",'\"').csv(\n",
    "    str(sorted(DATA_DIR.glob(\"*_UkraineCombinedTweetsDeduped.csv\"))[0])\n",
    ").limit(3)\n",
    "\n",
    "print(sample.columns)\n",
    "sample.select(\"tweetid\",\"text\",\"language\").show(3, truncate=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a76672e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 291 / 291 files\n",
      "Stage 15 |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë| 38/40 (95%)\n",
      "Done ‚Üí F:\\UK-Russia\\jupyter\\output\\tweets_clean.parquet\n"
     ]
    }
   ],
   "source": [
    "import threading, time, requests\n",
    "from pyspark.sql.types import LongType, BooleanType\n",
    "\n",
    "csv_files = [str(f) for f in sorted(DATA_DIR.glob(\"*_UkraineCombinedTweetsDeduped.csv\"))]\n",
    "print(f\"{len(csv_files)} files\")\n",
    "\n",
    "df = (\n",
    "    spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"multiLine\", \"true\")\n",
    "    .option(\"escape\", '\"')\n",
    "    .option(\"mode\", \"PERMISSIVE\")\n",
    "    .csv(csv_files)\n",
    "    .select(\n",
    "        F.col(\"tweetid\").cast(LongType()),\n",
    "        F.col(\"text\"),\n",
    "        F.col(\"language\"),\n",
    "        F.col(\"username\"),\n",
    "        F.col(\"retweetcount\").cast(LongType()),\n",
    "        F.col(\"is_retweet\").cast(BooleanType()),\n",
    "        F.col(\"tweetcreatedts\"),\n",
    "        F.col(\"hashtags\"),\n",
    "        F.col(\"followers\").cast(LongType()),\n",
    "    )\n",
    "    .filter(F.col(\"tweetid\").isNotNull())\n",
    "    .filter(F.col(\"language\") == \"en\")\n",
    "    .withColumn(\"text\", F.trim(F.regexp_replace(\"text\", r\"(\\s*#\\w+)+\\s*$\", \"\")))\n",
    "    .filter(F.length(\"text\") > 0)\n",
    "    .dropDuplicates([\"tweetid\"])\n",
    ")\n",
    "\n",
    "# progress monitor nh·ªè\n",
    "done = {\"v\": False}\n",
    "def _monitor():\n",
    "    app = spark.sparkContext.applicationId\n",
    "    prev = -1\n",
    "    while not done[\"v\"]:\n",
    "        try:\n",
    "            stages = [s for s in requests.get(\n",
    "                f\"http://localhost:4040/api/v1/applications/{app}/stages\", timeout=2\n",
    "            ).json() if s[\"status\"] == \"ACTIVE\"]\n",
    "            if stages:\n",
    "                s = stages[0]\n",
    "                n, t = s[\"numCompleteTasks\"], s[\"numTasks\"]\n",
    "                if n != prev:\n",
    "                    pct = n/t*100 if t else 0\n",
    "                    print(f\"\\r  stage {s['stageId']}  {'‚ñà'*int(pct//5)+'‚ñë'*(20-int(pct//5))}  {n}/{t}\", end=\"\", flush=True)\n",
    "                    prev = n\n",
    "        except: pass\n",
    "        time.sleep(2)\n",
    "\n",
    "threading.Thread(target=_monitor, daemon=True).start()\n",
    "df.write.mode(\"overwrite\").parquet(str(PARQUET_OUT))\n",
    "done[\"v\"] = True\n",
    "print(f\"\\ndone ‚Üí {PARQUET_OUT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c13c6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clean rows: 11,099,751\n",
      "+-------------------+--------------------------------------------------------------------------------+--------+--------------+------------+----------+-------------------+--------------------------------------------------------------------------------+---------+\n",
      "|            tweetid|                                                                            text|language|      username|retweetcount|is_retweet|     tweetcreatedts|                                                                        hashtags|followers|\n",
      "+-------------------+--------------------------------------------------------------------------------+--------+--------------+------------+----------+-------------------+--------------------------------------------------------------------------------+---------+\n",
      "|1560416650746142721|@Kenyans No one wants to be associated with dictators in #Russia. That‚Äôs a cr...|      en| logic19827474|           0|     false|2022-08-19 00:01:35|[{'text': 'Russia', 'indices': [57, 64]}, {'text': 'Russia', 'indices': [89, ...|       34|\n",
      "|1560416771022082049|Exclusive : #Russian ammunition warehouse exploded near #Tymonovo https://t.c...|      en|TeesriJungNews|           1|     false|2022-08-19 00:02:04|[{'text': 'Russian', 'indices': [12, 20]}, {'text': 'Tymonovo', 'indices': [5...|     3522|\n",
      "|1560417172819673088|                                                  @AVindman Stay SAFE!!!\\n‚ù§üá∫üá¶‚ù§|      en|  drkatraphael|           0|     false|2022-08-19 00:03:39|[{'text': 'UkraineUnderSeige', 'indices': [29, 47]}, {'text': 'RussiaIsATerro...|    27402|\n",
      "|1560417511585316865|EPIC TROLL!... Ukrainian Music to Annoy Putin https://t.co/ayjaVJXjKq via @Yo...|      en|   warzones166|           0|     false|2022-08-19 00:05:00|[{'text': 'ukrainewar', 'indices': [85, 96]}, {'text': 'UkraineRussianWar', '...|        6|\n",
      "|1560420530087288833|Possibly the first video of the American M982 Excalibur in action guided shel...|      en|        weeiup|           4|     false|2022-08-19 00:17:00|[{'text': 'UkraineRussia', 'indices': [226, 240]}, {'text': 'Crimea', 'indice...|       23|\n",
      "+-------------------+--------------------------------------------------------------------------------+--------+--------------+------------+----------+-------------------+--------------------------------------------------------------------------------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "result = spark.read.parquet(str(PARQUET_OUT))\n",
    "print(f\"{result.count():,} rows\")\n",
    "result.show(5, truncate=80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
